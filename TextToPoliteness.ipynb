{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file provides an interface to \n",
    "a pre-trained politeness SVM. \n",
    "\"\"\"\n",
    "\n",
    "#####\n",
    "# Ensure the proper python dependencies exist\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    sys.stderr.write(\"Package not found: Politeness model requires python package numpy\\n\")\n",
    "    sys.exit(2)\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy.sparse import csr_matrix\n",
    "except:\n",
    "    sys.stderr.write(\"Package not found: Politeness model requires python package scipy\\n\")\n",
    "    sys.exit(2)\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "except:\n",
    "    sys.stderr.write(\"Package not found: Politeness model requires python package scikit-learn\\n\")\n",
    "    sys.exit(2)\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "except:\n",
    "    sys.stderr.write(\"Package not found: Politeness model requires python package nltk\\n\")\n",
    "    sys.exit(2)\n",
    "\n",
    "####\n",
    "# Check versions for sklearn, scipy, numpy, nltk\n",
    "# Don't error out, just notify\n",
    "\n",
    "packages2versions = [(\"scikit-learn\", sklearn, \"0.15.1\"), (\"numpy\", np, \"1.9.0\"), (\"nltk\", nltk, \"3.0.0\"), (\"scipy\", scipy, \"0.12.0\")]\n",
    "\n",
    "for name, package, expected_v in packages2versions:\n",
    "    if package.__version__ < expected_v:\n",
    "        sys.stderr.write(\"Warning: package '%s', expected version >= %s, detected %s. Code functionality not guaranteed.\\n\" % (name, expected_v, package.__version__))\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "from politeness.features.vectorizer import PolitenessFeatureVectorizer\n",
    "\n",
    "\n",
    "####\n",
    "# Serialized model filename\n",
    "\n",
    "MODEL_FILENAME = 'politeness/politeness-svm.p'\n",
    "####\n",
    "# Load model, initialize vectorizer\n",
    "\n",
    "clf = cPickle.load(open(MODEL_FILENAME))\n",
    "vectorizer = PolitenessFeatureVectorizer()\n",
    "\n",
    "def score(request):\n",
    "    \"\"\"\n",
    "    :param request - The request document to score\n",
    "    :type request - dict with 'sentences' and 'parses' field\n",
    "        sample (taken from test_documents.py)--\n",
    "        {\n",
    "            'sentences': [\n",
    "                \"Have you found the answer for your question?\", \n",
    "                \"If yes would you please share it?\"\n",
    "            ],\n",
    "            'parses': [\n",
    "                [\"csubj(found-3, Have-1)\", \"dobj(Have-1, you-2)\", \"root(ROOT-0, found-3)\", \"det(answer-5, the-4)\", \"dobj(found-3, answer-5)\", \"poss(question-8, your-7)\", \"prep_for(found-3, question-8)\"], \n",
    "                [\"prep_if(would-3, yes-2)\", \"root(ROOT-0, would-3)\", \"nsubj(would-3, you-4)\", \"ccomp(would-3, please-5)\", \"nsubj(it-7, share-6)\", \"xcomp(please-5, it-7)\"]\n",
    "            ]\n",
    "        } \n",
    "\n",
    "    returns class probabilities as a dict\n",
    "        {\n",
    "            'polite': float, \n",
    "            'impolite': float\n",
    "        }\n",
    "    \"\"\"\n",
    "    # vectorizer returns {feature-name: value} dict\n",
    "    features = vectorizer.features(request)\n",
    "    fv = [features[f] for f in sorted(features.iterkeys())]\n",
    "    # Single-row sparse matrix\n",
    "    X = csr_matrix(np.asarray([fv]))\n",
    "    probs = clf.predict_proba(X)\n",
    "    # Massage return format\n",
    "    probs = {\"polite\": probs[0][1], \"impolite\": probs[0][0]}\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Text:  Have you found the answer for your question? If yes would you please share it?\n",
      "\tP(polite) = 0.719\n",
      "\tP(impolite) = 0.281\n",
      "\n",
      "\n",
      "====================\n",
      "Text:  Sorry :) I dont want to hack the system!! :) is there another way?\n",
      "\tP(polite) = 0.640\n",
      "\tP(impolite) = 0.360\n",
      "\n",
      "\n",
      "====================\n",
      "Text:  What are you trying to do?  Why can't you just store the \"Range\"?\n",
      "\tP(polite) = 0.034\n",
      "\tP(impolite) = 0.966\n",
      "\n",
      "\n",
      "====================\n",
      "Text:  This was supposed to have been moved to &lt;url&gt; per the cfd. why wasn't it moved?\n",
      "\tP(polite) = 0.068\n",
      "\tP(impolite) = 0.932\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megh/anaconda/envs/py27/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from politeness.test_documents import TEST_DOCUMENTS\n",
    "\n",
    "for doc in TEST_DOCUMENTS:\n",
    "    \n",
    "    probs = score(doc)\n",
    "\n",
    "    print \"====================\"\n",
    "    print \"Text: \", doc['text']\n",
    "    print \"\\tP(polite) = %.3f\" % probs['polite']\n",
    "    print \"\\tP(impolite) = %.3f\" % probs['impolite']\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Punkt knows that the periods in Mr. Smith and Johann S. Bachdo not mark sentence boundaries.', 'And sometimes sentencescan start with non-capitalized words.', 'i is a good variablename.']\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "text = \"Punkt knows that the periods in Mr. Smith and Johann S. Bach\\\n",
    "do not mark sentence boundaries.  And sometimes sentences\\\n",
    "can start with non-capitalized words.  i is a good variable\\\n",
    "name.\"\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "print(sent_detector.tokenize(text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json, requests\n",
    "class StanfordCoreNLP:\n",
    "    \"\"\"\n",
    "    Modified from https://github.com/smilli/py-corenlp\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, server_url):\n",
    "        # TODO: Error handling? More checking on the url?\n",
    "        if server_url[-1] == '/':\n",
    "            server_url = server_url[:-1]\n",
    "        self.server_url = server_url\n",
    " \n",
    "    def annotate(self, text, properties=None):\n",
    "        assert isinstance(text, str)\n",
    "        if properties is None:\n",
    "            properties = {}\n",
    "        else:\n",
    "            assert isinstance(properties, dict)\n",
    " \n",
    "        # Checks that the Stanford CoreNLP server is started.\n",
    "        try:\n",
    "            requests.get(self.server_url)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            raise Exception('Check whether you have started the CoreNLP server e.g.\\n'\n",
    "                            '$ cd <path_to_core_nlp_folder>/stanford-corenlp-full-2016-10-31/ \\n'\n",
    "                            '$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port <port> -timeout <timeout_in_ms>')\n",
    " \n",
    "        data = text.encode()\n",
    "        r = requests.post(\n",
    "            self.server_url, params={\n",
    "                'properties': str(properties)\n",
    "            }, data=data, headers={'Connection': 'close'})\n",
    "        output = r.text\n",
    "        if ('outputFormat' in properties\n",
    "            and properties['outputFormat'] == 'json'):\n",
    "            try:\n",
    "                output = json.loads(output, encoding='utf-8', strict=True)\n",
    "            except:\n",
    "                pass\n",
    "        return output\n",
    "\n",
    "def dep_parse_sentence(sentence):\n",
    "    # The StanfordCoreNLP server is running on http://127.0.0.1:9000\n",
    "    nlp = StanfordCoreNLP('http://127.0.0.1:9000')\n",
    "    # Json response of all the annotations\n",
    "    output = nlp.annotate(sentence, properties={\n",
    "        \"annotators\": \"parse,sentiment\",\n",
    "        \"outputFormat\": \"json\"\n",
    "        # Only split the sentence at End Of Line. We assume that this method only takes in one single sentence.\n",
    "        #\"ssplit.eolonly\": \"true\",\n",
    "        # Setting enforceRequirements to skip some annotators and make the process faster\n",
    "        #\"enforceRequirements\": \"false\"\n",
    "    }\n",
    "                         )\n",
    "    # Only care about the result of the first sentence because we assume we only annotate a single sentence in this method.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input [{u'dep': u'ROOT',\n",
    "#   u'dependent': 3,\n",
    "#   u'dependentGloss': u'would',\n",
    "#   u'governor': 0,\n",
    "#   u'governorGloss': u'ROOT'},... ]\n",
    "\n",
    "# output [\"root(ROOT-0, would-3)\", ... ]\n",
    "#l = [\"prep_if(would-3, yes-2)\", \"root(ROOT-0, would-3)\", \"nsubj(would-3, you-4)\", \"ccomp(would-3, please-5)\", \"nsubj(it-7, share-6)\", \"xcomp(please-5, it-7)\"]\n",
    "#for ll in l:\n",
    "#    print(ll)\n",
    "out = sentiment_analysis_on_sentence(\"If yes would you please share it?\")\n",
    "depsList = []\n",
    "deps = out['sentences'][0]['basicDependencies']\n",
    "for dep in deps:\n",
    "    d = dep\n",
    "    newDepFmt = d['dep'].lower() + \"(\" + d['governorGloss']+\"-\"+str(d['governor'])+\", \"+d['dependentGloss']+\"-\"+str(d['dependent'])+\")\"\n",
    "    depsList.append(newDepFmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#         \"text\": \"What are you trying to do?  Why can't you just store the \\\"Range\\\"?\",\n",
    "#         \"sentences\": [\n",
    "#             \"What are you trying to do?\",\n",
    "#             \"Why can't you just store the 'Range'?\"\n",
    "#         ],\n",
    "#         \"parses\": [\n",
    "#             [\"dep(trying-4, What-1)\", \"aux(trying-4, are-2)\", \"nsubj(trying-4, you-3)\", \"xsubj(do-6, you-3)\", \"root(ROOT-0, trying-4)\", \"aux(do-6, to-5)\", \"xcomp(trying-4, do-6)\"],\n",
    "#             [\"advmod(ca-2, Why-1)\", \"advcl(store-6, ca-2)\", \"neg(ca-2, n't-3)\", \"nsubj(store-6, you-4)\", \"advmod(store-6, just-5)\", \"root(ROOT-0, store-6)\", \"det(Range-9, the-7)\", \"dobj(store-6, Range-9)\"]\n",
    "#         ]\n",
    "# }\n",
    "# putting it all together\n",
    "\n",
    "import nltk.data\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def getpoliteImpoliteScores(text):\n",
    "    dataDict = {}\n",
    "    dataDict[\"text\"] = text\n",
    "    sentences = sent_detector.tokenize(dataDict[\"text\"].strip())\n",
    "    dataDict[\"sentences\"] = sentences\n",
    "    parses = []\n",
    "    for sentence in sentences:\n",
    "        out = dep_parse_sentence(sentence)\n",
    "        depsList = []\n",
    "        deps = out['sentences'][0]['basicDependencies']\n",
    "        for dep in deps:\n",
    "            d = dep\n",
    "            newDepFmt = d['dep'].lower() + \"(\" + d['governorGloss']+\"-\"+str(d['governor'])+\", \"+d['dependentGloss']+\"-\"+str(d['dependent'])+\")\"\n",
    "            depsList.append(newDepFmt)\n",
    "        parses.append(depsList)\n",
    "    dataDict[\"parses\"] = parses\n",
    "    return score(dataDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_data=open('./out/HomeKitchenCleanBOWSentimentDict.json').read()\n",
    "HomeKitchenCleanBOWSentimentDict = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B000REMVGK\n",
      "B001NJ4J6I\n",
      "B0018O2XFC\n",
      "B000QJ1MZC\n"
     ]
    }
   ],
   "source": [
    "HomeKitchenCleanBOWSentimentPolitenessDict = {}\n",
    "for asin in HomeKitchenCleanBOWSentimentDict:\n",
    "    try:\n",
    "        HomeKitchenCleanBOWSentimentPolitenessDict[asin] = HomeKitchenCleanBOWSentimentDict[asin]\n",
    "        descriptionPoliteImpoliteScores = getpoliteImpoliteScores(str(HomeKitchenCleanBOWSentimentDict[asin]['description']))\n",
    "        reviewPoliteImpoliteScores = getpoliteImpoliteScores(str(HomeKitchenCleanBOWSentimentDict[asin]['Best review']))\n",
    "        HomeKitchenCleanBOWSentimentPolitenessDict[asin]['descriptionPoliteness'] = descriptionPoliteImpoliteScores['polite']\n",
    "        HomeKitchenCleanBOWSentimentPolitenessDict[asin]['reviewPoliteness'] = reviewPoliteImpoliteScores['polite']\n",
    "    except Exception:\n",
    "        print(asin)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Best review': u\"I opted for regular shipping as I didn't really want it to arrive the day before Christmas (for an extra $69 too). However, that's exactly when it did arrive! It was a gift to my daughter & son-in-law. They assembled it Christmas night after we left and had it together in no time. They love it!\",\n",
       " u'description': u'Versatile, functional and stylish all describe this kitchen island with its cottage oak finish. The island not only provides added kitchen work surface and storage but with its 11-1/2-inch breakfast bar extended also provides a convenient place to grab a bite to eat or enjoy a morning cup of coffee. Find adjustable shelving on both ends of the island as well as two utility drawers and two cabinets, each with two adjustable shelves yielding lots of storage. Enhancing the style and cottage oak finish, the island features both hand applied physical and finish distressing. Overall construction is of sustainable hardwood with a clear coat finish helping to protect against wear from normal use. Features include convenient drop leaf that raises to provide dining/serving space, antique brass finished hardware, easy glide storage drawers, raised detail cabinet doors with adjustable shelves inside and open storage on ends with an adjustable shelf. Requires assembly. Measures 49-3/4-inch width by 26-1/2-inch depth by 36-1/2-inch height with drop leaf extended island is 36-inch depth.',\n",
       " u'descriptionBow': [u'versatile',\n",
       "  u'functional',\n",
       "  u'stylish',\n",
       "  u'describe',\n",
       "  u'kitchen',\n",
       "  u'island',\n",
       "  u'cottage',\n",
       "  u'oak',\n",
       "  u'finish',\n",
       "  u'island',\n",
       "  u'provides',\n",
       "  u'added',\n",
       "  u'kitchen',\n",
       "  u'work',\n",
       "  u'surface',\n",
       "  u'storage',\n",
       "  u'breakfast',\n",
       "  u'bar',\n",
       "  u'extended',\n",
       "  u'also',\n",
       "  u'provides',\n",
       "  u'convenient',\n",
       "  u'place',\n",
       "  u'grab',\n",
       "  u'bite',\n",
       "  u'eat',\n",
       "  u'enjoy',\n",
       "  u'morning',\n",
       "  u'cup',\n",
       "  u'coffee',\n",
       "  u'find',\n",
       "  u'adjustable',\n",
       "  u'shelving',\n",
       "  u'ends',\n",
       "  u'island',\n",
       "  u'well',\n",
       "  u'two',\n",
       "  u'utility',\n",
       "  u'drawers',\n",
       "  u'two',\n",
       "  u'cabinets',\n",
       "  u'two',\n",
       "  u'adjustable',\n",
       "  u'shelves',\n",
       "  u'yielding',\n",
       "  u'lots',\n",
       "  u'storage',\n",
       "  u'enhancing',\n",
       "  u'style',\n",
       "  u'cottage',\n",
       "  u'oak',\n",
       "  u'finish',\n",
       "  u'island',\n",
       "  u'features',\n",
       "  u'hand',\n",
       "  u'applied',\n",
       "  u'physical',\n",
       "  u'finish',\n",
       "  u'distressing',\n",
       "  u'overall',\n",
       "  u'construction',\n",
       "  u'sustainable',\n",
       "  u'hardwood',\n",
       "  u'clear',\n",
       "  u'coat',\n",
       "  u'finish',\n",
       "  u'helping',\n",
       "  u'protect',\n",
       "  u'wear',\n",
       "  u'normal',\n",
       "  u'use',\n",
       "  u'features',\n",
       "  u'include',\n",
       "  u'convenient',\n",
       "  u'drop',\n",
       "  u'leaf',\n",
       "  u'raises',\n",
       "  u'provide',\n",
       "  u'diningserving',\n",
       "  u'space',\n",
       "  u'antique',\n",
       "  u'brass',\n",
       "  u'finished',\n",
       "  u'hardware',\n",
       "  u'easy',\n",
       "  u'glide',\n",
       "  u'storage',\n",
       "  u'drawers',\n",
       "  u'raised',\n",
       "  u'detail',\n",
       "  u'cabinet',\n",
       "  u'doors',\n",
       "  u'adjustable',\n",
       "  u'shelves',\n",
       "  u'inside',\n",
       "  u'open',\n",
       "  u'storage',\n",
       "  u'ends',\n",
       "  u'adjustable',\n",
       "  u'shelf',\n",
       "  u'requires',\n",
       "  u'assembly',\n",
       "  u'measures',\n",
       "  u'width',\n",
       "  u'depth',\n",
       "  u'height',\n",
       "  u'drop',\n",
       "  u'leaf',\n",
       "  u'extended',\n",
       "  u'island',\n",
       "  u'depth'],\n",
       " 'descriptionPoliteness': 0.80358403311415505,\n",
       " u'descriptionSentiment': {u'compound': 0.8979,\n",
       "  u'neg': 0.054,\n",
       "  u'neu': 0.797,\n",
       "  u'pos': 0.148},\n",
       " u'reviewBow': [u'opted',\n",
       "  u'regular',\n",
       "  u'shipping',\n",
       "  u'nt',\n",
       "  u'really',\n",
       "  u'want',\n",
       "  u'arrive',\n",
       "  u'day',\n",
       "  u'christmas',\n",
       "  u'extra',\n",
       "  u'however',\n",
       "  u'exactly',\n",
       "  u'arrive',\n",
       "  u'gift',\n",
       "  u'daughter',\n",
       "  u'soninlaw',\n",
       "  u'assembled',\n",
       "  u'christmas',\n",
       "  u'night',\n",
       "  u'left',\n",
       "  u'together',\n",
       "  u'time',\n",
       "  u'love'],\n",
       " 'reviewPoliteness': 0.35184635959282529,\n",
       " u'reviewSentiment': {u'compound': 0.8268,\n",
       "  u'neg': 0.0,\n",
       "  u'neu': 0.697,\n",
       "  u'pos': 0.303},\n",
       " u'salesRank': {u'Home &amp; Kitchen': 216329},\n",
       " u'title': u'Home Styles 5004-94 Kitchen Island, Distressed Oak Finish'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HomeKitchenCleanBOWSentimentPolitenessDict['B003ISJ4L2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./out/HomeKitchenCleanBOWSentimentPolitenessDict.json', 'w') as outfile:\n",
    "    json.dump(HomeKitchenCleanBOWSentimentPolitenessDict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
