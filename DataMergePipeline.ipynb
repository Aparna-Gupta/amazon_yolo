{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load dataset raveled json file.\n",
    "def load_data(filepath):\n",
    "    data = json.load(open(filepath))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to uravel json data into pandas dataframe\n",
    "def convertDictToJson(data):\n",
    "    finalDict = {}\n",
    "    for asin in data:\n",
    "        finalDict[asin] = {}\n",
    "        if ('price' in data[asin]) and ('reviewPoliteness' in data[asin]):\n",
    "            # Politeness\n",
    "            #finalDict[asin]['reviewPoliteness'] = data[asin][\"reviewPoliteness\"]\n",
    "            #finalDict[asin]['descriptionPoliteness'] = data[asin][\"descriptionPoliteness\"]\n",
    "        \n",
    "            # ARI\n",
    "            finalDict[asin]['readabilityIndexDescription'] = data[asin][\"descriptionARI\"]\n",
    "            finalDict[asin]['readabilityIndexReview'] = data[asin][\"reviewARI\"]\n",
    "        \n",
    "            # Sentiment - Review\n",
    "            finalDict[asin]['reviewSentimentNeg'] = data[asin][\"reviewSentiment\"]['neg']\n",
    "            finalDict[asin]['reviewSentimentNeu'] = data[asin][\"reviewSentiment\"]['neu']\n",
    "            finalDict[asin]['reviewSentimentPos'] = data[asin][\"reviewSentiment\"]['pos']\n",
    "            finalDict[asin]['reviewSentimentCom'] = data[asin][\"reviewSentiment\"]['compound']\n",
    "        \n",
    "            # Sentiment - Description\n",
    "            finalDict[asin]['descriptionSentimentNeg'] = data[asin][\"descriptionSentiment\"]['neg']\n",
    "            finalDict[asin]['descriptionSentimentNeu'] = data[asin][\"descriptionSentiment\"]['neu']\n",
    "            finalDict[asin]['descriptionSentimentPos'] = data[asin][\"descriptionSentiment\"]['pos']\n",
    "            finalDict[asin]['descriptionSentimentCom'] = data[asin][\"descriptionSentiment\"]['compound']\n",
    "        \n",
    "            #Empath - Description\n",
    "            for empath_key in data[asin][\"descriptionEmpath\"]:\n",
    "                finalDict[asin]['empath_description_'+str(empath_key)] = data[asin][\"descriptionEmpath\"][empath_key]\n",
    "            #Empath - Review\n",
    "            for empath_key in data[asin][\"reviewEmpath\"]:\n",
    "                finalDict[asin]['empath_review_'+str(empath_key)] = data[asin][\"reviewEmpath\"][empath_key]\n",
    "        \n",
    "            # Price\n",
    "            finalDict[asin]['price'] = data[asin][\"price\"]\n",
    "            # Brand\n",
    "            #finalDict[asin]['brand'] = data[asin]['brand']\n",
    "        \n",
    "            # Rating\n",
    "            finalDict[asin]['Rating'] = data[asin][\"Rating\"]\n",
    "        \n",
    "            # Separate column for Sales Rank and Product Category.\n",
    "            d = (data[asin][\"salesRank\"]).items()\n",
    "            for key,value in d:\n",
    "                finalDict[asin]['category'] = key\n",
    "                finalDict[asin]['salesRank'] = value\n",
    "    \n",
    "    finalDf = pd.DataFrame.from_dict(finalDict, orient='index')\n",
    "    return finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20239, 402)\n",
      "            readabilityIndexDescription  readabilityIndexReview  \\\n",
      "3812028492                        87.01                   92.93   \n",
      "B00000J9DU                        51.28                   75.71   \n",
      "B00000JHQ2                        34.63                   90.60   \n",
      "B00004YK0Y                        29.21                   68.81   \n",
      "B00004YK10                        30.36                   70.33   \n",
      "\n",
      "            reviewSentimentNeg  reviewSentimentNeu  reviewSentimentPos  \\\n",
      "3812028492               0.000               0.712               0.288   \n",
      "B00000J9DU               0.124               0.767               0.109   \n",
      "B00000JHQ2               0.114               0.802               0.083   \n",
      "B00004YK0Y               0.071               0.822               0.107   \n",
      "B00004YK10               0.000               0.753               0.247   \n",
      "\n",
      "            reviewSentimentCom  descriptionSentimentNeg  \\\n",
      "3812028492              0.9468                    0.039   \n",
      "B00000J9DU             -0.0770                    0.056   \n",
      "B00000JHQ2             -0.2389                    0.000   \n",
      "B00004YK0Y              0.2641                    0.000   \n",
      "B00004YK10              0.9583                    0.000   \n",
      "\n",
      "            descriptionSentimentNeu  descriptionSentimentPos  \\\n",
      "3812028492                    0.814                    0.147   \n",
      "B00000J9DU                    0.824                    0.119   \n",
      "B00000JHQ2                    0.694                    0.306   \n",
      "B00004YK0Y                    0.873                    0.127   \n",
      "B00004YK10                    0.824                    0.176   \n",
      "\n",
      "            descriptionSentimentCom    ...      empath_review_giving  \\\n",
      "3812028492                   0.7356    ...                  0.000000   \n",
      "B00000J9DU                   0.9230    ...                  0.000000   \n",
      "B00000JHQ2                   0.8955    ...                  0.000000   \n",
      "B00004YK0Y                   0.5423    ...                  0.025974   \n",
      "B00004YK10                   0.7351    ...                  0.014085   \n",
      "\n",
      "            empath_review_contentment  empath_review_writing  \\\n",
      "3812028492                        0.0                    0.0   \n",
      "B00000J9DU                        0.0                    0.0   \n",
      "B00000JHQ2                        0.0                    0.0   \n",
      "B00004YK0Y                        0.0                    0.0   \n",
      "B00004YK10                        0.0                    0.0   \n",
      "\n",
      "            empath_review_rural  empath_review_positive_emotion  \\\n",
      "3812028492                  0.0                        0.049180   \n",
      "B00000J9DU                  0.0                        0.000000   \n",
      "B00000JHQ2                  0.0                        0.034483   \n",
      "B00004YK0Y                  0.0                        0.012987   \n",
      "B00004YK10                  0.0                        0.028169   \n",
      "\n",
      "            empath_review_order  price  Rating                category  \\\n",
      "3812028492                  0.0  51.38     5.0  Health & Personal Care   \n",
      "B00000J9DU                  0.0  32.85     2.0  Health & Personal Care   \n",
      "B00000JHQ2                  0.0   4.99     4.0  Health & Personal Care   \n",
      "B00004YK0Y                  0.0   0.91     1.0  Health & Personal Care   \n",
      "B00004YK10                  0.0   3.35     5.0  Health & Personal Care   \n",
      "\n",
      "            salesRank  \n",
      "3812028492      23511  \n",
      "B00000J9DU       8382  \n",
      "B00000JHQ2      13433  \n",
      "B00004YK0Y      71445  \n",
      "B00004YK10        364  \n",
      "\n",
      "[5 rows x 402 columns]\n"
     ]
    }
   ],
   "source": [
    "# Health\n",
    "dataset_health = load_data('./data/reviews_Health_and_Personal_Care_5_Health & Personal Care_clean.json')\n",
    "df_health = convertDictToJson(dataset_health)\n",
    "# Food\n",
    "dataset_food = load_data('./data/reviews_Grocery_and_Gourmet_Food_5_Grocery & Gourmet Food_clean.json')\n",
    "df_food = convertDictToJson(dataset_food)\n",
    "# Beauty\n",
    "dataset_beauty = load_data('./data/reviews_Beauty_5_Beauty_clean.json')\n",
    "df_beauty = convertDictToJson(dataset_beauty)\n",
    "# Tools\n",
    "dataset_tools = load_data('./data/reviews_Tools_and_Home_Improvement_5_Sports &amp; Outdoors_clean.json')\n",
    "df_tools = convertDictToJson(dataset_tools)\n",
    "frames = [df_health,df_food,df_beauty,df_tools]\n",
    "result = pd.concat(frames)\n",
    "print(result.shape)\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Unnamed column to ASIN - hack.\n",
    "result.to_csv('./dummy_dataset.csv')\n",
    "test_df = pd.read_csv('./dummy_dataset.csv')\n",
    "test_df.columns = [x if not x.startswith('Unnamed') else 'ASIN' for x in test_df.columns ]\n",
    "test_df.to_csv('./data/final_regression_dataset.csv',index=False)\n",
    "# remove the dummy file\n",
    "os.remove('./dummy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20239, 403)\n",
      "['Beauty', 'Grocery & Gourmet Food', 'Health & Personal Care', 'Sports &amp; Outdoors']\n",
      "(12140, 404)\n",
      "                ASIN  readabilityIndexDescription  readabilityIndexReview  \\\n",
      "category                                                                    \n",
      "Beauty    B001MA0QY2                        58.82                   93.68   \n",
      "Beauty    B00I46E8DC                        50.33                   91.82   \n",
      "Beauty    B000FS05VG                        43.73                  100.58   \n",
      "Beauty    B00016XJ4M                      -215.78                   79.40   \n",
      "Beauty    B002MSN3QQ                        59.23                   63.15   \n",
      "\n",
      "          reviewSentimentNeg  reviewSentimentNeu  reviewSentimentPos  \\\n",
      "category                                                               \n",
      "Beauty                 0.066               0.817               0.118   \n",
      "Beauty                 0.000               0.777               0.223   \n",
      "Beauty                 0.033               0.618               0.349   \n",
      "Beauty                 0.026               0.743               0.231   \n",
      "Beauty                 0.089               0.588               0.323   \n",
      "\n",
      "          reviewSentimentCom  descriptionSentimentNeg  \\\n",
      "category                                                \n",
      "Beauty                0.6941                    0.022   \n",
      "Beauty                0.8685                    0.017   \n",
      "Beauty                0.9720                    0.000   \n",
      "Beauty                0.9664                    0.079   \n",
      "Beauty                0.9339                    0.045   \n",
      "\n",
      "          descriptionSentimentNeu  descriptionSentimentPos  ...    \\\n",
      "category                                                    ...     \n",
      "Beauty                      0.745                    0.233  ...     \n",
      "Beauty                      0.786                    0.197  ...     \n",
      "Beauty                      0.923                    0.077  ...     \n",
      "Beauty                      0.802                    0.120  ...     \n",
      "Beauty                      0.809                    0.146  ...     \n",
      "\n",
      "          empath_review_contentment  empath_review_writing  \\\n",
      "category                                                     \n",
      "Beauty                          0.0                    0.0   \n",
      "Beauty                          0.0                    0.0   \n",
      "Beauty                          0.0                    0.0   \n",
      "Beauty                          0.0                    0.0   \n",
      "Beauty                          0.0                    0.0   \n",
      "\n",
      "          empath_review_rural  empath_review_positive_emotion  \\\n",
      "category                                                        \n",
      "Beauty                    0.0                        0.000000   \n",
      "Beauty                    0.0                        0.025000   \n",
      "Beauty                    0.0                        0.019231   \n",
      "Beauty                    0.0                        0.023256   \n",
      "Beauty                    0.0                        0.048780   \n",
      "\n",
      "          empath_review_order  price  Rating  category  salesRank  class  \n",
      "category                                                                  \n",
      "Beauty               0.010101  53.59     5.0    Beauty          1      1  \n",
      "Beauty               0.000000  27.95     4.0    Beauty          5      1  \n",
      "Beauty               0.000000  23.92     4.0    Beauty          6      1  \n",
      "Beauty               0.000000  10.48     5.0    Beauty         10      1  \n",
      "Beauty               0.000000  22.67     2.0    Beauty         13      1  \n",
      "\n",
      "[5 rows x 404 columns]\n"
     ]
    }
   ],
   "source": [
    "# compile data for the classification task\n",
    "# add a class column to the dataset\n",
    "# aggregate all dataframes into one dataframe for classification\n",
    "\n",
    "def covertRegression2ClassificationDataframe(df):\n",
    "    numProdsInThirtyPercent = int(df.shape[0] * 0.3)\n",
    "    top30Percentdf = df.nsmallest(numProdsInThirtyPercent, 'salesRank')\n",
    "    top30Percentdf[\"class\"] = 1 \n",
    "    bot30Percentdf = df.nlargest(numProdsInThirtyPercent, 'salesRank')\n",
    "    bot30Percentdf[\"class\"] = 0\n",
    "    return pd.concat([top30Percentdf,bot30Percentdf])\n",
    "\n",
    "\n",
    "# read the entire dataset\n",
    "data = pd.read_csv(\"data/final_dataset.csv\")\n",
    "print(data.shape)\n",
    "# split data into dataframes for each category\n",
    "data.sort_values(by = ['category'], inplace=True)\n",
    "# set the index to be this and don't drop\n",
    "data.set_index(keys = ['category'], drop=False,inplace=True)\n",
    "# get a list of all product categories\n",
    "categories = data['category'].unique().tolist()\n",
    "print(categories)\n",
    "\n",
    "# for each category compute the top and bottom 30% products by sales \n",
    "allClassificationDFs = []\n",
    "for key in categories:\n",
    "    classificationDFForKey = covertRegression2ClassificationDataframe(data[:][data.category == key])\n",
    "    allClassificationDFs.append(classificationDFForKey)\n",
    "\n",
    "# combine all the data into one dataframe and store it \n",
    "classificationData = pd.concat(allClassificationDFs)\n",
    "print(classificationData.shape)\n",
    "print(classificationData.head())\n",
    "classificationData.to_csv('./data/final_classification_dataset.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
